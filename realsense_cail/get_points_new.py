#!/usr/bin/env python3
import sys
import time
import logging
import math
import numpy as np
import cv2
import pyrealsense2 as rs
import rtde_receive
import json  # 1. å¯¼å…¥jsonæ¨¡å—

# --- Charuco æ¿å‚æ•° ---
# (æ­¤éƒ¨åˆ†æ— æ”¹åŠ¨)
CHARUCO_DICT = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_1000)
CHARUCO_BOARD = cv2.aruco.CharucoBoard(
    size=(7, 9),
    dictionary=CHARUCO_DICT,
    squareLength=0.027,     # æ ¼å­çš„ç‰©ç†è¾¹é•¿ï¼ˆç±³ï¼‰
    markerLength=0.02     # ArUcoå­æ ‡è®°çš„ç‰©ç†è¾¹é•¿ï¼ˆç±³ï¼‰
)
DETECT_PARAMS = cv2.aruco.DetectorParameters()

def get_camera_frame(pipeline):
    """ä»RealSenseç›¸æœºè·å–å½©è‰²å›¾åƒå¸§å’Œå†…å‚"""
    frames = pipeline.wait_for_frames()
    color_frame = frames.get_color_frame()
    if not color_frame:
        return None, None, None

    intr = color_frame.profile.as_video_stream_profile().intrinsics
    camera_matrix = np.array([
        [intr.fx, 0, intr.ppx],
        [0, intr.fy, intr.ppy],
        [0, 0, 1]
    ])
    dist_coeffs = np.array(intr.coeffs)
    color_image = np.asanyarray(color_frame.get_data())
    
    return color_image, camera_matrix, dist_coeffs

def draw_charuco_visuals(img, camera_matrix, dist_coeffs):
    """åœ¨å›¾åƒä¸Šæ£€æµ‹å¹¶ç»˜åˆ¶ChArUcoæ¿çš„è¯†åˆ«ç»“æœ"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    corners, ids, _ = cv2.aruco.detectMarkers(gray, CHARUCO_DICT, parameters=DETECT_PARAMS)

    is_detected = False
    if ids is not None and len(ids) > 0:
        cv2.aruco.drawDetectedMarkers(img, corners, ids)
        retval, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(
            markerCorners=corners,
            markerIds=ids,
            image=gray,
            board=CHARUCO_BOARD
        )
        
        if retval > 4:
            cv2.aruco.drawDetectedCornersCharuco(img, charuco_corners, charuco_ids)
            # å°è¯•ä¼°è®¡ä½å§¿ä»¥ç»˜åˆ¶åæ ‡è½´ï¼Œæä¾›æ›´å¥½çš„è§†è§‰åé¦ˆ
            success, rvec, tvec = cv2.aruco.estimatePoseCharucoBoard(
                rvec=np.empty(1), # å ä½ç¬¦
                tvec=np.empty(1),  # å ä½ç¬¦
                charucoCorners=charuco_corners,
                charucoIds=charuco_ids,
                board=CHARUCO_BOARD,
                cameraMatrix=camera_matrix,
                distCoeffs=dist_coeffs
            )
            if success:
                cv2.drawFrameAxes(img, camera_matrix, dist_coeffs, rvec, tvec, 0.1)
                is_detected = True
                
    return img, is_detected

def main():
    logging.basicConfig(level=logging.INFO)
    
    # --- åˆå§‹åŒ– RealSense ç›¸æœº ---
    pipeline = rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
    pipeline.start(config)
    logging.info("RealSense ç›¸æœºåˆå§‹åŒ–å®Œæˆã€‚")

    # --- åˆå§‹åŒ–æœºå™¨äººé€šä¿¡ ---
    try:
        rtde_r = rtde_receive.RTDEReceiveInterface("192.168.101.101")
        logging.info("å·²è¿æ¥åˆ°æœºå™¨äººã€‚")
    except Exception as e:
        logging.error(f"è¿æ¥æœºå™¨äººå¤±è´¥: {e}")
        pipeline.stop()
        return

    collected_points = []
    
    print("\n" + "="*60)
    print(" ğŸ¤– ç”¨äºæ‰‹çœ¼æ ‡å®šçš„è§†è§‰è¾…åŠ©é‡‡ç‚¹å·¥å…· ğŸ‘ï¸")
    print("-" * 60)
    print("æ“ä½œè¯´æ˜:")
    print(" 1. ä½¿ç”¨ç¤ºæ•™å™¨æ‰‹åŠ¨ç§»åŠ¨æœºå™¨äººã€‚")
    print(" 2. è§‚å¯Ÿå®æ—¶è§†é¢‘çª—å£ï¼Œæ‰¾åˆ°ä¸€ä¸ªèƒ½æ¸…æ™°æ£€æµ‹åˆ°æ ‡å®šæ¿çš„è‰¯å¥½ä½å§¿ã€‚")
    print(" 3. æŒ‰ä¸‹ã€ç©ºæ ¼é”®ã€‘ä¿å­˜å½“å‰æœºå™¨äººçš„TCPä½å§¿ã€‚")
    print(" 4. æŒ‰ä¸‹ã€Qé”®ã€‘å®Œæˆé‡‡ç‚¹å¹¶é€€å‡ºç¨‹åºã€‚")
    print("=" * 60 + "\n")
    
    try:
        while True:
            color_image, camera_matrix, dist_coeffs = get_camera_frame(pipeline)
            if color_image is None:
                continue

            vis_image, is_detected = draw_charuco_visuals(color_image, camera_matrix, dist_coeffs)
            
            window_title = "Live View | Press [SPACE] to Save | [Q] to Quit"
            if not is_detected:
                cv2.putText(vis_image, "BOARD NOT DETECTED", (10, 30), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

            cv2.imshow(window_title, vis_image)
            
            key = cv2.waitKey(1) & 0xFF

            if key == ord('q'):
                logging.info("æŒ‰ä¸‹ 'Q' é”®ï¼Œæ­£åœ¨ç»“æŸé‡‡ç‚¹...")
                break
            
            if key == ord(' '):
                pose = rtde_r.getActualTCPPose()
                collected_points.append(pose)
                logging.info(f"ç‚¹ {len(collected_points)} å·²ä¿å­˜: {pose}")

    finally:
        # 5. æ¸…ç†å¹¶æ‰“å°/ä¿å­˜æœ€ç»ˆç»“æœ
        cv2.destroyAllWindows()
        pipeline.stop()
        logging.info("ç¨‹åºç»“æŸã€‚")

        print("\n" + "="*60)
        print(f"é‡‡é›†å®Œæˆã€‚æ€»å…±ä¿å­˜äº† {len(collected_points)} ä¸ªç‚¹ã€‚")

        if collected_points:
            # 2. å°†é‡‡é›†åˆ°çš„ç‚¹ä½å†™å…¥JSONæ–‡ä»¶
            output_filename = "collected_robot_poses.json"
            try:
                with open(output_filename, 'w') as f:
                    # ä½¿ç”¨json.dumpå†™å…¥æ–‡ä»¶ï¼Œindent=4ä½¿å…¶æ ¼å¼åŒ–ï¼Œæ›´æ˜“è¯»
                    json.dump(collected_points, f, indent=4)
                logging.info(f"æ‰€æœ‰ç‚¹ä½å·²æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶: {output_filename}")
            except Exception as e:
                logging.error(f"å†™å…¥JSONæ–‡ä»¶å¤±è´¥: {e}")

            # (å¯é€‰) ä¿ç•™åŸæœ‰çš„ç»ˆç«¯æ‰“å°è¾“å‡ºï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥çœ‹
            print("æ‚¨å¯ä»¥å°†ä¸‹é¢çš„æ•°ç»„å¤åˆ¶åˆ°æ‚¨çš„ä¸»æ ‡å®šè„šæœ¬ä¸­:")
            print("\npoints = np.array([")
            for point in collected_points:
                formatted_point = ", ".join([f"{p:.8f}" for p in point])
                print(f"    [{formatted_point}],")
            print("])\n")
        
        print("="*60 + "\n")

if __name__ == "__main__":
    main()