import os
import cv2
import numpy as np
import sys
from datetime import datetime

# å°†srcç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­ï¼Œä»¥ä¾¿å¯ä»¥å¯¼å…¥æˆ‘ä»¬è‡ªå·±çš„APIæ¨¡å—
# æ³¨æ„ï¼šæ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨çš„é¡¹ç›®ç»“æ„è°ƒæ•´æ­¤è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from src.perception_node.realsense_api import RealsenseAPI
from perception_api_detect import StainPerceptionAPI


def generate_and_save_grasp_mask(model_weights_path,
                                 output_path="/home/wmx/graspnet-baseline/mask.png",
                                 confidence_threshold=0.5):
    """
    ã€ä¿®æ­£ç‰ˆã€‘
    Capture a frame, detect stains, build a binary mask for 'solid' class only,
    and return (mask_path, grasp_pos_cam). The grasp position (in camera frame, meters)
    is chosen from the best 'solid' detection (by confidence).

    Returns:
        Tuple[str | None, dict | None]:
            - saved mask file path (or None on fatal error)
            - grasp_pos_cam as a dict {'x':, 'y':, 'z':} in meters (or None if no solid found)
    """
    import os
    import numpy as np
    import cv2

    print("--- æŒ‰éœ€ç”Ÿæˆå¹¶ä¿å­˜æ©ç å›¾ (ä»…é™ Solid) ---")

    realsense_api = None
    perception_api = None
    center_pose = None  # ç¡®ä¿å®šä¹‰

    try:
        # ä¾èµ–ï¼šä½ éœ€è¦åœ¨å…¶ä»–ä½ç½®æ­£ç¡®å¯¼å…¥/å®ç° StainPerceptionAPI, RealsenseAPI, camera_intrinsics
        perception_api = StainPerceptionAPI(model_weights_path)
        realsense_api = RealsenseAPI()
        
        # ã€ä¿®æ”¹ç‚¹ 1ã€‘: è°ƒç”¨ detect_stains éœ€è¦ä¼ å…¥ç›¸æœºå†…å‚
        # å‡è®¾ realsense_api å¯ä»¥æä¾›å†…å‚
        camera_intrinsics = realsense_api.get_intrinsics()

        print("ğŸ“· æ­£åœ¨æ•è·ç¨³å®šçš„å›¾åƒå¸§...")
        bgr_image, depth_image_m = realsense_api.get_frames()
        if bgr_image is None:
            print("âŒ é”™è¯¯ï¼šæ— æ³•ä»ç›¸æœºæ•è·å›¾åƒã€‚")
            return None, None
        print("âœ… å›¾åƒæ•è·æˆåŠŸã€‚")

        print("ğŸš€ æ­£åœ¨è¿è¡Œæ±¡æ¸æ£€æµ‹...")
        # ã€ä¿®æ”¹ç‚¹ 2ã€‘: æ¥æ”¶ detect_stains è¿”å›çš„å­—å…¸
        detections_dict = perception_api.detect_stains(bgr_image, depth_image_m, camera_intrinsics, confidence_threshold)

        h, w = bgr_image.shape[:2]
        combined_mask = np.zeros((h, w), dtype=np.uint8)

        # ã€ä¿®æ”¹ç‚¹ 3ã€‘: ä»å­—å…¸ä¸­å®‰å…¨åœ°è·å– 'solid' æ±¡æ¸åˆ—è¡¨
        solid_stains_list = detections_dict.get('solid', [])
        
        if solid_stains_list:
            print(f"ğŸ” æ£€æµ‹åˆ° {len(solid_stains_list)} ä¸ª 'solid' æ±¡æ¸ã€‚")

            # ã€ä¿®æ”¹ç‚¹ 4ã€‘: ç›´æ¥åœ¨ solid_stains_list ä¸Šå¾ªç¯å’Œæ’åº
            # æŒ‰ç½®ä¿¡åº¦é™åºæ’åºï¼Œé€‰å‡ºæœ€ä¼˜çš„
            solid_stains_list.sort(key=lambda s: s.get('confidence', 0), reverse=True)
            
            best_solid_stain = solid_stains_list[0]
            center_pose = best_solid_stain.get("position_m")
            
            print(f"âœ… å·²é€‰æ‹©æœ€ä¼˜ 'solid' ç›®æ ‡ï¼Œç½®ä¿¡åº¦: {best_solid_stain.get('confidence')}")
            if center_pose is None:
                print("âš ï¸ æœ€ä¼˜ solid æ£€æµ‹ç¼ºå°‘ position_m æ•°æ®ã€‚")

            # ã€ä¿®æ”¹ç‚¹ 5ã€‘: éå†æ‰€æœ‰ solid æ±¡æ¸ï¼Œæ ¹æ® bbox ç”Ÿæˆå¹¶åˆå¹¶æ©ç 
            for stain in solid_stains_list:
                bbox = stain.get("bbox_pixels")
                if bbox:
                    x1, y1, x2, y2 = bbox
                    cv2.rectangle(combined_mask, (x1, y1), (x2, y2), 255, -1)
        else:
            print("âš ï¸ æœªå‘ç° 'solid' ç±»åˆ«ï¼Œæ©ç å°†ä¸ºå…¨é»‘ã€‚")
            center_pose = None

        # ä¿å­˜æ©ç 
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜æ©ç å›¾è‡³: '{output_path}'")
        ok = cv2.imwrite(output_path, combined_mask)
        if not ok:
            print("âŒ cv2.imwrite å¤±è´¥ã€‚")
            return None, None
        print("âœ… ä¿å­˜æˆåŠŸï¼")

        return output_path, False

    except Exception as e:
        import traceback
        print(f"âŒ å‘ç”Ÿäº†ä¸¥é‡é”™è¯¯: {e}")
        traceback.print_exc() # æ‰“å°è¯¦ç»†çš„é”™è¯¯è¿½æº¯ä¿¡æ¯
        return None, None



if __name__ == "__main__":
    from PIL import Image

    # --- é…ç½®å‚æ•° ---
    YOLO_MODEL_PATH = "/home/wmx/GraspNet-based-on-YOLO-for-specific-object-recognition-and-grasp/yolo8l_batch8_run1.pt"
    OUTPUT_MASK_PATH = "/home/wmx/graspnet-baseline/mask.png"
    CONF_THRESHOLD = 0.5

    # --- æ‰§è¡Œä¸»å‡½æ•° ---
    saved_mask_path ,completed_grasp= generate_and_save_grasp_mask(
        model_weights_path=YOLO_MODEL_PATH,
        output_path=OUTPUT_MASK_PATH,
        confidence_threshold=CONF_THRESHOLD
    )

    # --- å¤„ç†è¿”å›çš„è·¯å¾„ ---
    if saved_mask_path:
        print(f"\nâœ… æ©ç å·²æˆåŠŸç”Ÿæˆå¹¶ä¿å­˜åˆ°: {saved_mask_path}")
        print("ç°åœ¨æ¨¡æ‹Ÿæ‚¨çš„åŸå§‹è°ƒç”¨æµç¨‹...")
        try:
            workspace_mask = np.array(Image.open(saved_mask_path).resize((640, 480), Image.NEAREST))
            print(f"æˆåŠŸè¯»å–å¹¶è°ƒæ•´æ©ç å°ºå¯¸ä¸º: {workspace_mask.shape}")
            # åœ¨è¿™é‡Œå¯ä»¥ç»§ç»­ä½¿ç”¨ workspace_mask

            # (å¯é€‰) æ˜¾ç¤ºæœ€ç»ˆç”Ÿæˆçš„æ©ç å›¾æ¥éªŒè¯ç»“æœ
            cv2.imshow("Generated Solid-Only Mask", workspace_mask)
            print("æŒ‰ä»»æ„é”®é€€å‡ºæ˜¾ç¤º...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()

        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {saved_mask_path}")
        except Exception as e:
            print(f"âŒ è¯»å–æˆ–å¤„ç†å›¾åƒæ—¶å‡ºé”™: {e}")
    else:
        print("\nâŒ ç”Ÿæˆæ©ç æ–‡ä»¶å¤±è´¥ã€‚")